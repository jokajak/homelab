---
# defaults for ignition role
ignition_butane_version: 1.4.0
ignition_users:
- name: core
  ssh_authorized_keys:
  - '{{ ignition_ssh_pubkey }}'
  groups:
  - wheel
  - sudo
- name: josh
  ssh_authorized_keys:
  - '{{ ignition_ssh_pubkey }}'
  groups:
  - wheel
  - sudo
- name: ansible_svc
  ssh_authorized_keys:
  - '{{ ignition_ssh_pubkey }}'
  groups:
  - wheel
  - sudo

ignition_systemd_units:
# This installs k3s dependencies on boot
- name: "rpm-ostree-install-k3s-dependencies.service"
  enabled: true
  contents: |
    [Unit]
    Description=Install k3s dependencies
    Wants=network-online.target
    After=network-online.target
    # We run before `zincati.service` to avoid conflicting rpm-ostree
    # transactions.
    Before=zincati.service
    ConditionPathExists=|!/usr/bin/kubectl
    ConditionPathExists=|!/usr/share/selinux/packages/k3s.pp

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    ExecStart=rpm-ostree install --apply-live --allow-inactive --assumeyes kubectl k3s-selinux

    [Install]
    WantedBy=multi-user.target
# Installing python3 as a layered package with rpm-ostree
# So that we can orchestrate with ansible
- name: rpm-ostree-install-python3.service
  enabled: true
  contents: |
    [Unit]
    Description=Layer python3 with rpm-ostree
    # We run after `systemd-machine-id-commit.service` to ensure that
    # `ConditionFirstBoot=true` services won't rerun on the next boot.
    After=systemd-machine-id-commit.service
    Wants=network-online.target
    After=network-online.target
    # We run before `zincati.service` to avoid conflicting rpm-ostree
    # transactions.
    Before=zincati.service
    After=rpm-ostree-install-vim.service
    ConditionPathExists=!/var/lib/%N.stamp

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    # `--allow-inactive` ensures that rpm-ostree does not return an error
    # if the package is already installed. This is useful if the package is
    # added to the root image in a future Fedora CoreOS release as it will
    # prevent the service from failing.
    ExecStart=/usr/bin/rpm-ostree install --apply-live --allow-inactive python3 python3-selinux
    ExecStart=/bin/touch /var/lib/%N.stamp

    [Install]
    WantedBy=multi-user.target
# Installing vim as a layered package with rpm-ostree
- name: rpm-ostree-install-vim.service
  enabled: true
  contents: |
    [Unit]
    Description=Layer vim with rpm-ostree
    # We run after `systemd-machine-id-commit.service` to ensure that
    # `ConditionFirstBoot=true` services won't rerun on the next boot.
    After=systemd-machine-id-commit.service
    Wants=network-online.target
    After=network-online.target
    # We run before `zincati.service` to avoid conflicting rpm-ostree
    # transactions.
    Before=zincati.service
    After=rpm-ostree-install-k3s-dependencies.service
    ConditionPathExists=!/var/lib/%N.stamp

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    # `--allow-inactive` ensures that rpm-ostree does not return an error
    # if the package is already installed. This is useful if the package is
    # added to the root image in a future Fedora CoreOS release as it will
    # prevent the service from failing.
    ExecStart=/usr/bin/rpm-ostree install --apply-live --allow-inactive vim-enhanced
    ExecStart=/bin/touch /var/lib/%N.stamp

    [Install]
    WantedBy=multi-user.target
storage:
  files:
    # Set vim as default editor
    # We use `zz-` as prefix to make sure this is processed last in order to
    # override any previously set defaults.
    - path: /etc/profile.d/zz-default-editor.sh
      overwrite: true
      contents:
        inline: |
          export EDITOR=vim

ignition_storage_disks:
- # The link to the block device the OS was booted from.
  device: /dev/disk/by-id/coreos-boot-disk
  # We do not want to wipe the partition table since this is the primary
  # device.
  wipe_table: false
  partitions:
  - number: 4
    label: root
    size_mib: 16384
    resize: true
  - size_mib: 0
    # We assign a descriptive label to the partition. This is important
    # for referring to it in a device-agnostic way in other parts of the
    # configuration.
    label: var

ignition_storage_filesystems:
- path: /var
  device: /dev/disk/by-partlabel/var
  # We can select the filesystem we'd like.
  format: xfs
  # Ask Butane to generate a mount unit for us so that this filesystem
  # gets mounted in the real root.
  with_mount_unit: true
  wipe_filesystem: false  # preserve /var on reinstall (this is the default, but be explicit)

ignition_storage_files:
- path: /etc/yum.repos.d/kubernetes.repo
  mode: 0644
  contents:
    inline: |
      [kubernetes]
      name=Kubernetes
      baseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/
      enabled=1
      gpgcheck=1
      gpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key
      exclude=kubelet kubeadm cri-tools kubernetes-cni
- path: /etc/yum.repos.d/rancher-k3s-common.repo
  mode: 0644
  contents:
    inline: |
      [rancher-k3s-common-stable]
      name=Rancher K3s Common (stable)
      baseurl=https://rpm.rancher.io/k3s/stable/common/centos/8/noarch
      enabled=1
      gpgcheck=1
      repo_gpgcheck=0
      gpgkey=https://rpm.rancher.io/public.key
- path: /etc/rancher/k3s/kubelet.config
  mode: 0644
  contents:
    inline: |
      apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      shutdownGracePeriod: 60s
      shutdownGracePeriodCriticalPods: 10s
# Schedule automatic updates for 4am PT = 12pm UTC on weekends.
- path: /etc/zincati/config.d/55-updates-strategy.toml
  contents:
    inline: |
      [updates]
      strategy = "periodic"
      [[updates.periodic.window]]
      days = [ "Saturday", "Sunday" ]
      start_time = "22:00"
      length_minutes = 120
- path: /etc/zincati/config.d/51-rollout-wariness.toml
  contents:
    inline: |
      [identity]
      rollout_wariness = 0.25
- path: /etc/hostname
  mode: 0644
  contents:
    inline: '{{ ignition_hostname }}'
# Set vim as default editor
# We use `zz-` as prefix to make sure this is processed last in order to
# override any previously set defaults.
- path: /etc/profile.d/zz-default-editor.sh
  overwrite: true
  contents:
    inline: |
      export EDITOR=vim
# Configure k3s
- path: /etc/rancher/k3s/config.yaml
  overwrite: false
  contents:
    inline: |
      write-kubeconfig-mode: '0640'
      tls-san:
      - k8s.local
      # disable flannel in favor of cilium because let's do hard mode
      # using cilium because it uses eBPF which is new hotness
      flannel-backend: none
      # disable network policy in favor of cilium
      disable-network-policy: true
      disable:
      - servicelb  # disable servicelb in favor of metallb
      # configure a cluster cidr to support ipv6
      cluster-cidr: {{ k3s_ipv4_cluster_cidr }},{{ k3s_ipv6_cluster_prefix }}
      service-cidr: {{ k3s_ipv4_service_cidr }},{{ k3s_ipv6_service_prefix }}
      kube-controller-manager-arg:
      - node-cidr-mask-size-ipv4={{ k3s_node_cidr_mask_size_ipv4 }}
      - node-cidr-mask-size-ipv6={{ k3s_node_cidr_mask_size_ipv6 }}
      {% if k3s_token is defined %}token: {{ k3s_token }}{% endif %}

# generated by using `sha256sum <cidr>`
k3s_ipv6_cluster_prefix: 'fc00:473d:9f9c:6::/56'
k3s_ipv6_service_prefix: 'fc00:473d:9f9c:7::/112'
k3s_ipv4_cluster_cidr: '10.42.0.0/16'
k3s_ipv4_service_cidr: '10.43.0.0/16'
k3s_node_cidr_mask_size_ipv6: 96
k3s_node_cidr_mask_size_ipv4: 24

# coreos uses aarch64, k3s uses arm64
k3s_version: 1.27.4
k3s_arm64_source: https://github.com/k3s-io/k3s/releases/download/v{{ k3s_version }}%2Bk3s1/k3s-arm64
k3s_x86_64_source: https://github.com/k3s-io/k3s/releases/download/v{{ k3s_version }}%2Bk3s1/k3s
k3s_arm64_hash: sha256-f5ecea7b398a99aa1b03dd1960cd753bd3aed210b32aeca1197a790c1a188f24
k3s_x86_64_hash: sha256-7438aade7f5aaab3904f95333b67aa072cee28fa06748b6ee66ebcbd3e5b6bd3
